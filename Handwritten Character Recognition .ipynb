{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39wv47_hW1e0",
        "outputId": "dc8dc2e4-4973-447d-e2c3-b83155253681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 54ms/step - accuracy: 0.8697 - loss: 0.4226\n",
            "Epoch 2/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.9820 - loss: 0.0569\n",
            "Epoch 3/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 50ms/step - accuracy: 0.9874 - loss: 0.0391\n",
            "Epoch 4/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 47ms/step - accuracy: 0.9901 - loss: 0.0316\n",
            "Epoch 5/5\n",
            "\u001b[1m574/938\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.9931 - loss: 0.0224"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(10, activation='softmax')  # 10 classes for digits 0-9\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QRi7zcASaUzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "KJbaHQN1aUEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JC31ffThaaw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    # Reshape and normalize\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "\n",
        "    # One-hot encode labels\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "rq41uOSQabi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "wtbJK4JOakw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=2, batch_size=32)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "0xxHZMBuani4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "aoP1uvCHbmNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "rAsylSVkdvYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(r\"/content/A_Z Handwritten Data.csv\").astype('float32')\n",
        "print(data.head(10))"
      ],
      "metadata": {
        "id": "Wz3r5wE_d1Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('0',axis = 1)\n",
        "y = data['0']"
      ],
      "metadata": {
        "id": "9vpuMyvueDup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_x = np.reshape(train_x.values, (train_x.shape[0], 28,28))\n",
        "test_x = np.reshape(test_x.values, (test_x.shape[0], 28,28))\n",
        "print(\"Train data shape: \", train_x.shape)\n",
        "print(\"Test data shape: \", test_x.shape)\n"
      ],
      "metadata": {
        "id": "3cs415AYeIV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "word_dict = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X', 24:'Y',25:'Z'}"
      ],
      "metadata": {
        "id": "0kFGdXoCeMpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_int = np.int0(y)\n",
        "count = np.zeros(26, dtype='int')\n",
        "print(count)\n",
        "for i in y_int:\n",
        "   count[i] +=1"
      ],
      "metadata": {
        "id": "_CdT_d5nePh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alphabets = []\n",
        "for i in word_dict.values():\n",
        "    alphabets.append(i)"
      ],
      "metadata": {
        "id": "a8leTmnseSCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alphabets[1]"
      ],
      "metadata": {
        "id": "fUgXs1sUeUVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
        "ax.barh(alphabets, count)\n",
        "plt.xlabel(\"Number of elements \")\n",
        "plt.ylabel(\"Alphabets\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uj4WsIdNeW3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuff = shuffle(train_x[:10])\n",
        "fig, ax = plt.subplots(3,3, figsize = (10,10))\n",
        "axes = ax.flatten()\n",
        "for i in range(9):\n",
        "    shu = cv2.threshold(shuff[i], 30, 200, cv2.THRESH_BINARY)\n",
        "    axes[i].imshow(np.reshape(shuff[i], (28,28)), cmap=\"Greys\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eRy-BorJebDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2],1)\n",
        "\n",
        "print(\"New shape of train data: \", train_X.shape)\n",
        "test_X = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2],1)\n",
        "print(\"New shape of train data: \", test_X.shape)"
      ],
      "metadata": {
        "id": "sEvQD04iemMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "train_yOHE = to_categorical(train_y, num_classes = 26)\n",
        "print(\"New shape of train labels: \", train_yOHE.shape)\n",
        "test_yOHE = to_categorical(test_y, num_classes = 26)\n",
        "print(\"New shape of test labels: \", test_yOHE.shape)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "5S23n1XHe-SL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras import backend as k\n",
        "import tensorflow\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,activation =\"relu\"))\n",
        "model.add(Dense(128,activation =\"relu\"))\n",
        "model.add(Dense(26,activation =\"softmax\"))"
      ],
      "metadata": {
        "id": "PVvaEFWqe_8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_X, train_yOHE, epochs=1,  validation_data = (test_X,test_yOHE))"
      ],
      "metadata": {
        "id": "xT8aSIC0f_md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "model.save(r'model_hand.h5')"
      ],
      "metadata": {
        "id": "vikypnxRgFC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The validation accuracy is :\", history.history['val_accuracy'])\n",
        "print(\"The training accuracy is :\", history.history['accuracy'])\n",
        "print(\"The validation loss is :\", history.history['val_loss'])\n",
        "print(\"The training loss is :\", history.history['loss'])"
      ],
      "metadata": {
        "id": "AoYTVo4zgI7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3,3, figsize=(8,9))\n",
        "axes = axes.flatten()\n",
        "for i,ax in enumerate(axes):\n",
        "    img = np.reshape(test_X[i], (28,28))\n",
        "    ax.imshow(img, cmap=\"Greys\")\n",
        "\n",
        "    pred = word_dict[np.argmax(test_yOHE[i])]\n",
        "    ax.set_title(\"Prediction: \"+pred)\n",
        "    ax.grid()"
      ],
      "metadata": {
        "id": "65XYTiOKgOJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All the images are correct by the CNN model\n",
        "# Here we can upload our JPG image to the project and we will see it will work correctly or not\n",
        "# I put the Image \"W\" in the image\n",
        "# You can write your selected alphabet on paper and then click the image and upload it on the\n",
        "# Jupyter\n",
        "img = cv2.imread(r'/content/A.jpg')\n",
        "img_copy = img.copy()\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img = cv2.resize(img, (400,440))"
      ],
      "metadata": {
        "id": "jvoaUJPwhEZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gaussain Method used for Blur checking\n",
        "img_copy = cv2.GaussianBlur(img_copy, (7,7), 0)\n",
        "img_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
        "_, img_thresh = cv2.threshold(img_gray, 100, 255, cv2.THRESH_BINARY_INV)\n",
        "img_final = cv2.resize(img_thresh, (28,28))\n",
        "img_final =np.reshape(img_final, (1,28,28,1))"
      ],
      "metadata": {
        "id": "q3EVJaPBk13a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# All the images are correct by the CNN model\n",
        "# Here we can upload our JPG image to the project and we will see it will work correctly or not\n",
        "# I put the Image \"W\" in the image\n",
        "# You can write your selected alphabet on paper and then click the image and upload it on the\n",
        "# Jupyter\n",
        "img = cv2.imread(r'/content/A.jpg')\n",
        "img_copy = img.copy()\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img = cv2.resize(img, (400, 440))\n",
        "\n",
        "# ... (rest of the code remains the same)\n",
        "\n",
        "img_pred = word_dict[np.argmax(model.predict(img_final))]\n",
        "cv2.putText(img, \"Arslan's Prediction: \", (20, 25), cv2.FONT_HERSHEY_TRIPLEX, 0.7, color=(0, 0, 230))\n",
        "cv2.putText(img, \"New Predic: \" + img_pred, (20, 410), cv2.FONT_HERSHEY_DUPLEX, 1.3, color=(255, 0, 30))\n",
        "# Instead of cv2.imshow, use cv2_imshow from google.colab.patches\n",
        "from google.colab.patches import cv2_imshow  # Import the necessary function\n",
        "cv2_imshow(img)  # Display the image using cv2_imshow"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Xhi332VzlIff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All the images are correct by the CNN model\n",
        "# Here we can upload our JPG image to the project and we will see it will work correctly or not\n",
        "# I put the Image \"W\" in the image\n",
        "# You can write your selected alphabet on paper and then click the image and upload it on the\n",
        "img = cv2.imread(r'/content/w.jpg')\n",
        "img_copy = img.copy()\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img = cv2.resize(img, (400, 440))\n",
        "\n",
        "# ... (rest of the code remains the same)\n",
        "\n",
        "img_pred = word_dict[np.argmax(model.predict(img_final))]\n",
        "cv2.putText(img, \"Arslan's Prediction: \", (20, 25), cv2.FONT_HERSHEY_TRIPLEX, 0.7, color=(0, 0, 230))\n",
        "cv2.putText(img, \"New Predic: \" + img_pred, (20, 410), cv2.FONT_HERSHEY_DUPLEX, 1.3, color=(255, 0, 30))\n",
        "# Instead of cv2.imshow, use cv2_imshow from google.colab.patches\n",
        "from google.colab.patches import cv2_imshow  # Import the necessary function\n",
        "cv2_imshow(img)  # Display the image using cv2_imshow"
      ],
      "metadata": {
        "id": "GM5v73NZlq0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# All the images are correct by the CNN model\n",
        "# Here we can upload our JPG image to the project and we will see it will work correctly or not\n",
        "# I put the Image \"W\" in the image\n",
        "# You can write your selected alphabet on paper and then click the image and upload it on theT\n",
        "img = cv2.imread(r'/content/b.jpg')\n",
        "img_copy = img.copy()\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img = cv2.resize(img, (400, 440))\n",
        "\n",
        "# ... (rest of the code remains the same)\n",
        "\n",
        "img_pred = word_dict[np.argmax(model.predict(img_final))]\n",
        "cv2.putText(img, \"Arslan's Prediction: \", (20, 25), cv2.FONT_HERSHEY_TRIPLEX, 0.7, color=(0, 0, 230))\n",
        "cv2.putText(img, \"New Predic: \" + img_pred, (20, 410), cv2.FONT_HERSHEY_DUPLEX, 1.3, color=(255, 0, 30))\n",
        "# Instead of cv2.imshow, use cv2_imshow from google.colab.patches\n",
        "from google.colab.patches import cv2_imshow  # Import the necessary function\n",
        "cv2_imshow(img)  # Display the image using cv2_imshow"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "k1D2B1spl8wA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}